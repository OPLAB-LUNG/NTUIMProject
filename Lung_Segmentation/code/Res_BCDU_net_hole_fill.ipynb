{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pytorch version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import datasets, transforms, models\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "# import models as M\n",
    "import numpy as np\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import jaccard_score\n",
    "from sklearn.metrics import f1_score\n",
    "from scipy.ndimage.morphology import binary_erosion, binary_fill_holes\n",
    "# import tensorflow as tf\n",
    "from torch.utils.data import ConcatDataset, DataLoader, Subset, Dataset\n",
    "from IPython.display import HTML\n",
    "from base64 import b64encode\n",
    "import cv2\n",
    "import SimpleITK as sitk\n",
    "import nibabel as nib\n",
    "import skimage, skimage.morphology, skimage.data\n",
    "import copy\n",
    "import random\n",
    "import imageio as iio\n",
    "random.seed(42)\n",
    "\n",
    "class ConvLSTMCell(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, padding, activation, frame_size):\n",
    "        super(ConvLSTMCell, self).__init__()\n",
    "\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        # self.device = torch.device('cpu')\n",
    "\n",
    "        if activation == \"tanh\":\n",
    "            self.activation = torch.tanh\n",
    "        elif activation == \"relu\":\n",
    "            self.activation = torch.relu\n",
    "\n",
    "        self.conv = nn.Conv2d(\n",
    "            in_channels=in_channels + out_channels,\n",
    "            out_channels=4 * out_channels,\n",
    "            kernel_size=kernel_size,\n",
    "            padding=padding)\n",
    "\n",
    "        self.W_ci = nn.Parameter(torch.Tensor(out_channels, *frame_size))\n",
    "        self.W_co = nn.Parameter(torch.Tensor(out_channels, *frame_size))\n",
    "        self.W_cf = nn.Parameter(torch.Tensor(out_channels, *frame_size))\n",
    "\n",
    "        # Initialize weights using Xavier initialization\n",
    "        nn.init.xavier_uniform_(self.W_ci)\n",
    "        nn.init.xavier_uniform_(self.W_co)\n",
    "        nn.init.xavier_uniform_(self.W_cf)\n",
    "\n",
    "    def forward(self, X, H_prev, C_prev):\n",
    "        # print(X.shape, H_prev.shape)\n",
    "        conv_output = self.conv(torch.cat([X, H_prev], dim=1))\n",
    "        i_conv, f_conv, C_conv, o_conv = torch.chunk(conv_output, chunks=4, dim=1)\n",
    "\n",
    "        input_gate = torch.sigmoid(i_conv + self.W_ci * C_prev)\n",
    "        forget_gate = torch.sigmoid(f_conv + self.W_cf * C_prev)\n",
    "\n",
    "        # Current Cell output\n",
    "        C = forget_gate * C_prev + input_gate * self.activation(C_conv)\n",
    "\n",
    "        output_gate = torch.sigmoid(o_conv + self.W_co * C)\n",
    "\n",
    "        # Current Hidden State\n",
    "        H = output_gate * self.activation(C)\n",
    "\n",
    "        return H, C\n",
    "\n",
    "\n",
    "class ConvLSTM(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, padding, activation, frame_size, return_sequence=False):\n",
    "        super(ConvLSTM, self).__init__()\n",
    "\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        # self.device = torch.device('cpu')\n",
    "        self.out_channels = out_channels\n",
    "        self.return_sequence = return_sequence\n",
    "\n",
    "        # We will unroll this over time steps\n",
    "        self.convLSTMcell = ConvLSTMCell(in_channels, out_channels, kernel_size, padding, activation, frame_size)\n",
    "\n",
    "    def forward(self, X):\n",
    "        # X is a frame sequence (batch_size, seq_len, num_channels, height, width)\n",
    "\n",
    "        # Get the dimensions\n",
    "        batch_size, seq_len, channels, height, width = X.size()\n",
    "\n",
    "        # Initialize output\n",
    "        output = torch.zeros(batch_size, seq_len, self.out_channels, height, width, device=self.device)\n",
    "\n",
    "        # Initialize Hidden State\n",
    "        H = torch.zeros(batch_size, self.out_channels, height, width, device=self.device)\n",
    "\n",
    "        # Initialize Cell Input\n",
    "        C = torch.zeros(batch_size, self.out_channels, height, width, device=self.device)\n",
    "\n",
    "        # Unroll over time steps\n",
    "        for time_step in range(seq_len):\n",
    "            H, C = self.convLSTMcell(X[:, time_step, ...], H, C)\n",
    "            # H, C = self.convLSTMcell(X, H, C)\n",
    "            output[:, time_step, ...] = H\n",
    "\n",
    "        if not self.return_sequence:\n",
    "            output = torch.squeeze(output[:, -1, ...], dim=1)\n",
    "\n",
    "        return output\n",
    "\n",
    "class ConvBLSTM(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels,\n",
    "                 kernel_size, padding, activation, frame_size, return_sequence=False):\n",
    "        super(ConvBLSTM, self).__init__()\n",
    "        self.return_sequence = return_sequence\n",
    "        self.forward_cell = ConvLSTM(in_channels, out_channels//2, \n",
    "                                     kernel_size, padding, activation, frame_size, return_sequence=True)\n",
    "        self.backward_cell = ConvLSTM(in_channels, out_channels//2, \n",
    "                                     kernel_size, padding, activation, frame_size, return_sequence=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        y_out_forward = self.forward_cell(x)\n",
    "        reversed_idx = list(reversed(range(x.shape[1])))\n",
    "        y_out_reverse = self.backward_cell(x[:, reversed_idx, ...])[:, reversed_idx, ...]\n",
    "        output = torch.cat((y_out_forward, y_out_reverse), dim=2)\n",
    "        if not self.return_sequence:\n",
    "            output = torch.squeeze(output[:, -1, ...], dim=1)\n",
    "        return output\n",
    "\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     # (batch, sequence_length, channels, height, width)\n",
    "# x1 = torch.randn([8, 128, 64, 64])\n",
    "# x2 = torch.randn([8, 128, 64, 64])\n",
    "# x1 = torch.randn([8, 128, 64, 64]).cuda()\n",
    "# x2 = torch.randn([8, 128, 64, 64]).cuda()\n",
    "\n",
    "# cblstm = ConvBLSTM(in_channels=128, out_channels=64, kernel_size=(3, 3), padding=(1, 1), activation='tanh', frame_size=(64,64), return_sequence=True)\n",
    "# cblstm = ConvBLSTM(in_channels=128, out_channels=64, kernel_size=(3, 3), padding=(1, 1), activation='tanh', frame_size=(64,64), return_sequence=True).cuda()\n",
    "\n",
    "# x = torch.stack([x1, x2], dim=1)\n",
    "# print(x.shape)\n",
    "# out = cblstm(x)\n",
    "# print (out.shape)\n",
    "# out.sum().backward()\n",
    "\n",
    "class BCDUNet(nn.Module):\n",
    "    def __init__(self, input_dim=3, output_dim=3, num_filter=64, frame_size=(256, 256), bidirectional=False, norm='instance'):\n",
    "        super(BCDUNet, self).__init__()\n",
    "        self.num_filter = num_filter\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.frame_size = np.array(frame_size)\n",
    "\n",
    "        if norm == 'instance':\n",
    "            norm_layer = nn.InstanceNorm2d\n",
    "        else:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "\n",
    "        def conv_block(in_channels, out_channels):\n",
    "            return nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=1, padding=1),\n",
    "                norm_layer(out_channels),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1),\n",
    "                norm_layer(out_channels),\n",
    "                nn.ReLU(inplace=True)\n",
    "            )\n",
    "        \n",
    "        # Encoder\n",
    "        resnet34 = models.resnet34(pretrained=True)\n",
    "        filters = [64, 128, 256, 512]\n",
    "\n",
    "        # print(list(resnet34.children()))\n",
    "        \n",
    "\n",
    "        self.res_input = resnet34.conv1\n",
    "        self.res_bn1 = nn.BatchNorm2d(64)\n",
    "        self.res_bn2 = nn.BatchNorm2d(128)\n",
    "        self.res_bn3 = nn.BatchNorm2d(256)\n",
    "        self.res_bn4 = nn.BatchNorm2d(512)\n",
    "        self.res_relu = nn.ReLU(inplace=False)\n",
    "        self.res_maxpool = resnet34.maxpool\n",
    "        self.encoder1 = resnet34.layer2\n",
    "        self.encoder2 = resnet34.layer3\n",
    "        self.encoder3 = resnet34.layer4\n",
    "\n",
    "        self.bridge = nn.Sequential(\n",
    "            nn.Conv2d(filters[3], filters[3]*2, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(filters[3]*2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "            \n",
    "        )\n",
    "\n",
    "        # self.conv1 = conv_block(input_dim, num_filter)\n",
    "        # self.conv2 = conv_block(num_filter, num_filter * 2)\n",
    "        # self.conv3 = conv_block(num_filter * 2, num_filter * 4)\n",
    "        # self.conv4 = conv_block(num_filter * 4, num_filter * 8)\n",
    "        self.upconv3 = nn.ConvTranspose2d(num_filter * 8, num_filter * 4, kernel_size=2, stride=2)\n",
    "        self.upconv2 = nn.ConvTranspose2d(num_filter * 4, num_filter * 2, kernel_size=2, stride=2)\n",
    "        self.upconv1 = nn.ConvTranspose2d(num_filter * 2, num_filter, kernel_size=2, stride=2)\n",
    "        self.upconv0 = nn.ConvTranspose2d(num_filter, output_dim, kernel_size=2, stride=2)\n",
    "\n",
    "        self.conv3m = conv_block(num_filter * 8, num_filter * 4)\n",
    "        self.conv2m = conv_block(num_filter * 4, num_filter * 2)\n",
    "        self.conv1m = conv_block(num_filter * 2, num_filter)\n",
    "\n",
    "        self.conv0 = nn.Conv2d(output_dim, output_dim, kernel_size=1)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "        if bidirectional:\n",
    "            self.clstm1 = ConvBLSTM(num_filter*4, num_filter*2, (3, 3), (1,1), 'tanh', list(self.frame_size//4))\n",
    "            self.clstm2 = ConvBLSTM(num_filter*2, num_filter, (3, 3), (1,1), 'tanh', list(self.frame_size//2))\n",
    "            self.clstm3 = ConvBLSTM(num_filter, num_filter//2, (3, 3), (1,1), 'tanh', list(self.frame_size))\n",
    "        else:\n",
    "            self.clstm1 = ConvLSTM(num_filter*4, num_filter*2, (3, 3), (1,1), 'tanh', list(self.frame_size//4))\n",
    "            self.clstm2 = ConvLSTM(num_filter*2, num_filter, (3, 3), (1,1), 'tanh', list(self.frame_size//2))\n",
    "            self.clstm3 = ConvLSTM(num_filter, num_filter//2, (3, 3), (1,1), 'tanh', list(self.frame_size))\n",
    "\n",
    "    def forward(self, x):\n",
    "        N = self.frame_size\n",
    "\n",
    "        ## Encoder \n",
    "\n",
    "        # conv1 = self.conv1(x)\n",
    "        # pool1 = self.maxpool(conv1)\n",
    "        # conv2 = self.conv2(pool1)\n",
    "        # pool2 = self.maxpool(conv2)\n",
    "        # conv3 = self.conv3(pool2)\n",
    "        # pool3 = self.maxpool(conv3)\n",
    "        # conv4 = self.conv4(pool3)\n",
    "\n",
    "        # print(\"x:\", x.shape)\n",
    "        conv1 = self.res_input(x)\n",
    "        conv1 = self.res_relu(conv1)\n",
    "        conv1 = self.res_bn1(conv1)\n",
    "        # conv1 = self.res_maxpool(conv1)\n",
    "        # print(\"conv1:\", conv1.shape)\n",
    "        conv2 = self.encoder1(conv1)\n",
    "        conv2 = self.res_relu(conv2)\n",
    "        conv2 = self.res_bn2(conv2)\n",
    "        # print(\"conv2:\", conv2.shape)\n",
    "        conv3 = self.encoder2(conv2)\n",
    "        conv3 = self.res_bn3(conv3)\n",
    "        # print(\"conv3:\", conv3.shape)\n",
    "        conv4 = self.encoder3(conv3)\n",
    "        conv4 = self.res_bn4(conv4)\n",
    "        # conv4 = self.maxpool(conv4)\n",
    "        # print(\"conv4:\", conv4.shape)\n",
    "        \n",
    "        # c = self.bridge(conv4)\n",
    "        # print(c.shape)\n",
    "\n",
    "        ## Decoder\n",
    "        upconv3 = self.upconv3(conv4)\n",
    "        # print(\"upconv3:\", upconv3.shape, \"conv3:\", conv3.shape)\n",
    "        # concat3 = torch.cat((conv3, upconv3), 1)\n",
    "        # print(upconv3.size())\n",
    "        upconv32 = upconv3.unsqueeze(0).transpose(0, 1)\n",
    "        upconv32 = torch.cat([upconv32] * 2, dim=1)\n",
    "        # upconv32 = torch.cat([upconv32] * 3, dim=1)\n",
    "        concat3 = self.clstm1(upconv32)\n",
    "        concat3 = torch.cat((concat3, concat3), 1)\n",
    "        concat3 = torch.cat((conv3, concat3), 1)\n",
    "        conv3m = self.conv3m(concat3)\n",
    "        conv3m = self.relu(conv3m)\n",
    "\n",
    "        upconv2 = self.upconv2(conv3m)\n",
    "        # print(\"upconv2:\", upconv2.shape, \"conv2:\", conv2.shape)\n",
    "        # concat2 = torch.cat((conv2, upconv2), 1)\n",
    "        upconv22 = upconv2.unsqueeze(0).transpose(0, 1)\n",
    "        upconv22 = torch.cat([upconv22] * 2, dim=1)\n",
    "        # upconv22 = torch.cat([upconv22] * 3, dim=1)\n",
    "        concat2 = self.clstm2(upconv22)\n",
    "        concat2 = torch.cat((concat2, concat2), 1)\n",
    "        concat2 = torch.cat((conv2, concat2), 1)\n",
    "        conv2m = self.conv2m(concat2)\n",
    "        conv2m = self.relu(conv2m)\n",
    "\n",
    "        upconv1 = self.upconv1(conv2m)\n",
    "        # print(\"upconv1:\", upconv1.shape, \"conv1:\", conv1.shape)\n",
    "        # concat1 = torch.cat((conv1, upconv1), 1)\n",
    "        upconv12 = upconv1.unsqueeze(0).transpose(0, 1)\n",
    "        upconv22 = torch.cat([upconv22] * 2, dim=1)\n",
    "        # upconv12 = torch.cat([upconv12] * 3, dim=1)\n",
    "        concat1 = self.clstm3(upconv12)\n",
    "        concat1 = torch.cat((concat1, concat1), 1)\n",
    "        concat1 = torch.cat((conv1, concat1), 1)\n",
    "        conv1m = self.conv1m(concat1)\n",
    "        conv1m = self.relu(conv1m)\n",
    "\n",
    "        upconv0 = self.upconv0(conv1m)\n",
    "        conv0 = self.conv0(upconv0)\n",
    "        # print(\"conv0:\", conv0.shape, \"conv1m:\", conv1m.shape)\n",
    "\n",
    "        return conv0\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "\n",
    "def train_valid_split(data_set, valid_ratio, seed=42):\n",
    "    '''Split provided training data into training set and validation set'''\n",
    "    valid_set_size = int(valid_ratio * len(data_set)) \n",
    "    train_set_size = len(data_set) - valid_set_size\n",
    "    train_set, valid_set = random_split(data_set, [train_set_size, valid_set_size], generator=torch.Generator().manual_seed(seed))\n",
    "    return np.array(train_set), np.array(valid_set)\n",
    "\n",
    "class Lung_Dataset(Dataset):\n",
    "    '''\n",
    "    x: Features.\n",
    "    y: Targets, if none, do prediction.\n",
    "    '''\n",
    "    def __init__(self, x, y=None):\n",
    "        if y is None:\n",
    "            self.y = y\n",
    "        else:\n",
    "            self.y = torch.FloatTensor(y)\n",
    "        self.x = torch.FloatTensor(x)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.y is None:\n",
    "            return self.x[idx]\n",
    "        else:\n",
    "            return self.x[idx], self.y[idx]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "def run_segmentation(te_data):\n",
    "\n",
    "    amount = len(te_data)\n",
    "    # fig, ax = plt.subplots(amount, 5, figsize=[4*5, amount*5])\n",
    "    result = []\n",
    "    te_data  = np.expand_dims(te_data, axis=3)\n",
    "\n",
    "\n",
    "    # print('Dataset loaded')\n",
    "    #te_data2  = dataset_normalized(te_data)\n",
    "    te_data2 = te_data / 255\n",
    "    te_data2 = torch.tensor(te_data2).transpose(1, 3)\n",
    "    te_data2 = torch.cat([te_data2] * 3, dim=1).numpy()\n",
    "\n",
    "    def predict(test_loader, model, device):\n",
    "        model.eval() # Set your model to evaluation mode.\n",
    "        preds = []\n",
    "        pbar = tqdm(range(len(test_loader)*2))\n",
    "        pbar.set_description(\"Predicting\")\n",
    "        for x in test_loader:\n",
    "            x = x.to(device)                        \n",
    "            with torch.no_grad():                   \n",
    "                pred = model(x)                     \n",
    "                preds.append(pred.detach().cpu())   \n",
    "                pbar.update(1)\n",
    "        preds = torch.cat(preds, dim=0).numpy()  \n",
    "        return preds\n",
    "\n",
    "    # Set device\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    # device = torch.device(\"cpu\")\n",
    "\n",
    "    # Hyperparameters\n",
    "    input_dim = 3\n",
    "    output_dim = 3\n",
    "    num_filter = 64\n",
    "    frame_size = (256, 256)\n",
    "    bidirectional = True\n",
    "    norm = 'instance'\n",
    "    batch_size = 2\n",
    "    test_dataset = Lung_Dataset(te_data2)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    # print(len(test_loader))\n",
    "    \n",
    "    # print(\"Start predicting\")\n",
    "\n",
    "    # Evaluation loop\n",
    "    model = BCDUNet(input_dim, output_dim, num_filter, frame_size, bidirectional, norm).to(device)\n",
    "    model.load_state_dict(torch.load('model.pth', map_location=torch.device(\"cpu\")))\n",
    "    predictions = predict(test_loader, model, device) \n",
    "    # print(\"Predict ends\")\n",
    "\n",
    "    # Post-processing\n",
    "    predictions = np.squeeze(predictions)\n",
    "    predictions = torch.tensor(predictions).transpose(1, 3)\n",
    "    predictions = np.where(predictions<0.5, 1, 0)\n",
    "    # print(predictions.shape)\n",
    "    Estimated_lung = predictions[:,:,:,0]\n",
    "    Estimated_lung2 = copy.deepcopy(Estimated_lung)\n",
    "    \n",
    "    Estimated_lung, Estimated_lung2, Lung_mask = hole_filler(Estimated_lung, Estimated_lung2)\n",
    "    \n",
    "    # print(\"phase 1 hole filled\")\n",
    "\n",
    "    # print(Lung_mask)\n",
    "    Filled_Lung = copy.deepcopy(Lung_mask)\n",
    "    for k in tqdm(range(Filled_Lung.shape[0]), desc=\"Second phase filling\"):\n",
    "        # if k % 10 == 0:\n",
    "        #     print(\"Now at image\", k)\n",
    "        Filled_Lung[k] = scipy.ndimage.binary_dilation(Filled_Lung[k], iterations=5)\n",
    "        Filled_Lung[k] = scipy.ndimage.binary_erosion(Filled_Lung[k], iterations=5)\n",
    "        noFill = np.zeros((512, 512))\n",
    "        visited = np.zeros((512, 512))\n",
    "        queue = deque([(0, 0)])\n",
    "        while queue:\n",
    "            node = queue.popleft()\n",
    "            if visited[node[0]][node[1]] == 0:\n",
    "                visited[node[0]][node[1]] = 1\n",
    "                noFill[node[0]][node[1]] = 1\n",
    "                for d in [(-1, 0), (0, 1), (0, -1), (1, 0)]:\n",
    "                    if node[0]+d[0] >= 0 and node[0]+d[0] < 512 and node[1]+d[1] >= 0 and node[1]+d[1] < 512:\n",
    "                        # print(Estimated_lung[k][node[0]+d[0]][node[1]+d[1]])\n",
    "                        if Filled_Lung[k][node[0]+d[0]][node[1]+d[1]] == 0:\n",
    "                            queue.append((node[0]+d[0], node[1]+d[1]))\n",
    "        for i in range(512):\n",
    "            for j in range(512):\n",
    "                if noFill[i][j] != 1:\n",
    "                    Filled_Lung[k][i][j] = 1\n",
    "    \n",
    "    amount = len(te_data)\n",
    "    # print(\"phase 2 hole filled\", te_data.shape, Filled_Lung.shape, amount)\n",
    "    # print(np.squeeze(te_data[0]).shape, np.squeeze(Estimated_lung[0]).shape,\n",
    "    #       np.squeeze(Estimated_lung2[0]).shape, np.squeeze(Lung_mask[0]).shape,\n",
    "    #       np.squeeze(Filled_Lung[0]).shape)\n",
    "    # for idx in range(amount):\n",
    "    #     print(amount*run_count+idx)\n",
    "    #     ax[amount*run_count+idx, 0].imshow(np.squeeze(te_data[idx]), cmap='gray')\n",
    "    #     ax[amount*run_count+idx, 1].imshow(np.squeeze(Estimated_lung[idx]), cmap='gray')\n",
    "    #     ax[amount*run_count+idx, 2].imshow(np.squeeze(Estimated_lung2[idx]), cmap='gray')\n",
    "    #     ax[amount*run_count+idx, 3].imshow(np.squeeze(Lung_mask[idx]), cmap='gray')\n",
    "    #     ax[amount*run_count+idx, 4].imshow(np.squeeze(Filled_Lung[idx]), cmap='gray')\n",
    "    for idx in tqdm(range(amount), desc=\"Computing segmentation result\"):\n",
    "        # unique, counts = np.unique(Filled_Lung[idx], return_counts=True)\n",
    "        # print(dict(zip(unique, counts)))\n",
    "        # ax[idx, 3*run_count].imshow(np.squeeze(te_data[idx]), cmap='gray')\n",
    "        # ax[idx, 3*run_count+1].imshow(np.squeeze(Filled_Lung[idx]), cmap='gray')\n",
    "        # Filled_Lung[idx] = np.where(Filled_Lung[idx] == 0, 1000, Filled_Lung[idx])\n",
    "        seg_result =  np.squeeze(te_data[idx])*Filled_Lung[idx]\n",
    "        seg_result = seg_result.astype(int)\n",
    "        seg_result[seg_result == 0] = 1000\n",
    "        seg_result[seg_result >= 1000] = 1000\n",
    "        seg_result[seg_result <= -1000] = -1000\n",
    "        # seg_result[seg_result > 100] = 100\n",
    "        # print(seg_result)\n",
    "        # print(seg_result.shape)\n",
    "        # np.savetxt('./seg_result.txt', fmt='%.0f', X=seg_result.astype(np.int))\n",
    "        # ax[idx, 3*run_count+2].imshow(seg_result, cmap='gray')\n",
    "        result.append(seg_result)\n",
    "    result = np.stack(result, axis=0)\n",
    "    return result\n",
    "    \n",
    "    # plt.savefig(f'./wayne_aug_seg_result/sample_results_{int(e/2)+1}.png')\n",
    "    \n",
    "\n",
    "def run_segmentation_yolo_annotate(te_data, patient, idx, malignancy):\n",
    "    te_data  = np.expand_dims(te_data, axis=0)\n",
    "    te_data  = np.expand_dims(te_data, axis=3)\n",
    "    # print('Dataset loaded')\n",
    "    #te_data2  = dataset_normalized(te_data)\n",
    "    te_data2 = te_data / 255\n",
    "    te_data2 = torch.tensor(te_data2).transpose(1, 3)\n",
    "    te_data2 = torch.cat([te_data2] * 3, dim=1).numpy()\n",
    "\n",
    "    def predict(test_loader, model, device):\n",
    "        model.eval() # Set your model to evaluation mode.\n",
    "        preds = []\n",
    "        for x in test_loader:\n",
    "            x = x.to(device)                        \n",
    "            with torch.no_grad():                   \n",
    "                pred = model(x)                     \n",
    "                preds.append(pred.detach().cpu())   \n",
    "        preds = torch.cat(preds, dim=0).numpy()  \n",
    "        return preds\n",
    "\n",
    "    # Set device\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    # device = torch.device(\"cpu\")\n",
    "\n",
    "    # Hyperparameters\n",
    "    input_dim = 3\n",
    "    output_dim = 3\n",
    "    num_filter = 64\n",
    "    frame_size = (256, 256)\n",
    "    bidirectional = True\n",
    "    norm = 'instance'\n",
    "    batch_size = 1\n",
    "    test_dataset = Lung_Dataset(te_data2)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    # print(len(test_loader))\n",
    "    \n",
    "    # print(\"Start predicting\")\n",
    "\n",
    "    # Evaluation loop\n",
    "    model = BCDUNet(input_dim, output_dim, num_filter, frame_size, bidirectional, norm).to(device)\n",
    "    model.load_state_dict(torch.load('model.pth', map_location=torch.device(\"cpu\")))\n",
    "    predictions = predict(test_loader, model, device) \n",
    "    # print(\"Predict ends\")\n",
    "\n",
    "    # Post-processing\n",
    "    predictions = np.squeeze(predictions)\n",
    "    # predictions = torch.tensor(predictions).transpose(1, 3)\n",
    "    predictions = np.where(predictions>0.5, 1, 0)\n",
    "    # print(predictions.shape)\n",
    "    # Estimated_lung = predictions[:,:,:,0]\n",
    "    Estimated_lung = predictions\n",
    "    Estimated_lung2 = copy.deepcopy(Estimated_lung)\n",
    "    \n",
    "    Estimated_lung, Estimated_lung2, Lung_mask = hole_filler(Estimated_lung, Estimated_lung2)\n",
    "    # print(np.squeeze(te_data).shape, Estimated_lung.shape, Estimated_lung2.shape, Lung_mask.shape)\n",
    "    # print(\"phase 1 hole filled\")\n",
    "\n",
    "    Estimated_lung = np.flipud(np.rot90(Estimated_lung[0,:,:]))\n",
    "    Estimated_lung2 = np.flipud(np.rot90(Estimated_lung2[0,:,:]))\n",
    "    Lung_mask = np.flipud(np.rot90(Lung_mask[0,:,:]))\n",
    "    # print(Lung_mask)\n",
    "    # fig, ax = plt.subplots(1, 5, figsize=[20, 5])\n",
    "    # ax[0].imshow(np.squeeze(te_data), cmap='gray')\n",
    "    # ax[1].imshow(np.squeeze(Estimated_lung)[0,:,:], cmap='gray')\n",
    "    # ax[2].imshow(np.squeeze(Estimated_lung2)[0,:,:], cmap='gray')\n",
    "    # ax[3].imshow(np.squeeze(Lung_mask)[0,:,:], cmap='gray')\n",
    "    # ax[0].imshow(te_data, cmap='gray')\n",
    "    # ax[1].imshow(Estimated_lung, cmap='gray')\n",
    "    # ax[2].imshow(Estimated_lung2, cmap='gray')\n",
    "    # ax[3].imshow(Lung_mask, cmap='gray')\n",
    "\n",
    "    Filled_Lung = copy.deepcopy(Lung_mask)\n",
    "    Filled_Lung = scipy.ndimage.binary_dilation(Filled_Lung, iterations=5)\n",
    "    Filled_Lung = scipy.ndimage.binary_erosion(Filled_Lung, iterations=5)\n",
    "    noFill = np.zeros((512, 512))\n",
    "    visited = np.zeros((512, 512))\n",
    "    queue = deque([(0, 0)])\n",
    "    while queue:\n",
    "        node = queue.popleft()\n",
    "        if visited[node[0]][node[1]] == 0:\n",
    "            visited[node[0]][node[1]] = 1\n",
    "            noFill[node[0]][node[1]] = 1\n",
    "            for d in [(-1, 0), (0, 1), (0, -1), (1, 0)]:\n",
    "                if node[0]+d[0] >= 0 and node[0]+d[0] < 512 and node[1]+d[1] >= 0 and node[1]+d[1] < 512:\n",
    "                    # print(Estimated_lung[node[0]+d[0]][node[1]+d[1]])\n",
    "                    if Filled_Lung[node[0]+d[0]][node[1]+d[1]] == 0:\n",
    "                        queue.append((node[0]+d[0], node[1]+d[1]))\n",
    "    for i in range(512):\n",
    "        for j in range(512):\n",
    "            if noFill[i][j] != 1:\n",
    "                Filled_Lung[i][j] = 1\n",
    "                    \n",
    "    # ax[2].imshow(np.squeeze(te_data2), cmap='gray')\n",
    "\n",
    "    # print(\"phase 2 hole filled\", te_data2.shape, Filled_Lung.shape, amount)\n",
    "    seg_result =  np.squeeze(te_data)*Filled_Lung\n",
    "    seg_result = seg_result.astype(int)\n",
    "    # seg_result[seg_result == 0] = 1000\n",
    "    # ax[4].imshow(seg_result, cmap='gray')\n",
    "    img = Image.fromarray(seg_result)\n",
    "    img = img.convert('L')\n",
    "    os.makedirs(f\"./yolo_annotation/\", exist_ok=True)\n",
    "    img.save(f'./yolo_annotation/{patient}_{idx}_{malignancy}.png')\n",
    "\n",
    "def edge_clean(matrix):\n",
    "    for i in range(0, 5):\n",
    "        for j in range(0, 512):\n",
    "            matrix[i][j] = 0\n",
    "            matrix[j][i] = 0\n",
    "    for i in range(507, 512):\n",
    "        for j in range(0, 512):\n",
    "            matrix[i][j] = 0\n",
    "            matrix[j][i] = 0\n",
    "            \n",
    "    \n",
    "\n",
    "def hole_filler(Estimated_lung, Estimated_lung2):\n",
    "    # fig2,ax2 = plt.subplots(3, 4, figsize=[20, 15])\n",
    "    for k in tqdm(range(Estimated_lung.shape[0]), desc=\"First phase filling\"):\n",
    "        edge_clean(Estimated_lung[k])\n",
    "        edge_clean(Estimated_lung2[k])\n",
    "        Estimated_lung[k] = scipy.ndimage.binary_erosion(Estimated_lung[k], iterations=5)\n",
    "        Estimated_lung2[k] = scipy.ndimage.binary_erosion(Estimated_lung2[k], iterations=5)\n",
    "        noFill = np.zeros((512, 512))\n",
    "        visited = np.zeros((512, 512))\n",
    "        queue = deque([(0, 0)])\n",
    "        while queue:\n",
    "            node = queue.popleft()\n",
    "            if visited[node[0]][node[1]] == 0:\n",
    "                visited[node[0]][node[1]] = 1\n",
    "                noFill[node[0]][node[1]] = 1\n",
    "                for d in [(-1, 0), (0, 1), (0, -1), (1, 0)]:\n",
    "                    if node[0]+d[0] >= 0 and node[0]+d[0] < 512 and node[1]+d[1] >= 0 and node[1]+d[1] < 512:\n",
    "                        # print(Estimated_lung[k][node[0]+d[0]][node[1]+d[1]])\n",
    "                        if Estimated_lung[k][node[0]+d[0]][node[1]+d[1]] == 0:\n",
    "                            queue.append((node[0]+d[0], node[1]+d[1]))\n",
    "        # ax2[0, k].imshow(Estimated_lung[k], cmap='gray')\n",
    "        # ax2[1, k].imshow(noFill, cmap='gray')\n",
    "        for i in range(512):\n",
    "            for j in range(512):\n",
    "                if noFill[i][j] != 1:\n",
    "                    Estimated_lung[k][i][j] = 1\n",
    "        # ax2[2, k].imshow(Estimated_lung[k], cmap='gray')\n",
    "    Lung_mask = np.subtract(Estimated_lung, Estimated_lung2)\n",
    "    return Estimated_lung, Estimated_lung2, Lung_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1.3.6.1.4.1.14519.5.2.1.6279.6001.108197895896446896160048741492.mhd\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\oplab\\anaconda3\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\oplab\\anaconda3\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet34_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet34_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Predicting:  50%|█████     | 119/238 [04:20<04:20,  2.19s/it]\n",
      "First phase filling: 100%|██████████| 237/237 [03:57<00:00,  1.00s/it]\n",
      "Second phase filling: 100%|██████████| 237/237 [06:18<00:00,  1.60s/it]\n",
      "Computing segmentation result: 100%|██████████| 237/237 [00:00<00:00, 424.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(237, 512, 512)\n",
      "Saved\n",
      "=============\n",
      "2 1.3.6.1.4.1.14519.5.2.1.6279.6001.109002525524522225658609808059.mhd\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  50%|█████     | 161/322 [05:56<05:56,  2.21s/it]\n",
      "First phase filling: 100%|██████████| 321/321 [04:32<00:00,  1.18it/s]\n",
      "Second phase filling: 100%|██████████| 321/321 [08:43<00:00,  1.63s/it]\n",
      "Computing segmentation result: 100%|██████████| 321/321 [00:00<00:00, 454.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(321, 512, 512)\n",
      "Saved\n",
      "=============\n",
      "3 1.3.6.1.4.1.14519.5.2.1.6279.6001.111172165674661221381920536987.mhd\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  50%|█████     | 269/538 [10:00<10:00,  2.23s/it]\n",
      "First phase filling: 100%|██████████| 538/538 [07:16<00:00,  1.23it/s]\n",
      "Second phase filling: 100%|██████████| 538/538 [14:04<00:00,  1.57s/it]\n",
      "Computing segmentation result: 100%|██████████| 538/538 [00:01<00:00, 507.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(538, 512, 512)\n",
      "Saved\n",
      "=============\n",
      "4 1.3.6.1.4.1.14519.5.2.1.6279.6001.122763913896761494371822656720.mhd\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  50%|█████     | 124/248 [04:32<04:32,  2.20s/it]\n",
      "First phase filling: 100%|██████████| 247/247 [04:01<00:00,  1.02it/s]\n",
      "Second phase filling: 100%|██████████| 247/247 [06:15<00:00,  1.52s/it]\n",
      "Computing segmentation result: 100%|██████████| 247/247 [00:00<00:00, 451.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(247, 512, 512)\n",
      "Saved\n",
      "=============\n",
      "5 1.3.6.1.4.1.14519.5.2.1.6279.6001.124154461048929153767743874565.mhd\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  50%|█████     | 195/390 [07:09<07:09,  2.20s/it]\n",
      "First phase filling: 100%|██████████| 389/389 [05:51<00:00,  1.11it/s]\n",
      "Second phase filling: 100%|██████████| 389/389 [10:20<00:00,  1.60s/it]\n",
      "Computing segmentation result: 100%|██████████| 389/389 [00:00<00:00, 459.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(389, 512, 512)\n",
      "Saved\n",
      "=============\n",
      "6 1.3.6.1.4.1.14519.5.2.1.6279.6001.126121460017257137098781143514.mhd\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  47%|████▋     | 125/266 [04:42<05:13,  2.22s/it]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32me:\\LUNA\\Lung_segmentation\\Res_BCDU_net_hole_fill.ipynb Cell 5\u001b[0m line \u001b[0;36m<cell line: 6>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/LUNA/Lung_segmentation/Res_BCDU_net_hole_fill.ipynb#W4sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m \u001b[39m# row = int(e/2)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/LUNA/Lung_segmentation/Res_BCDU_net_hole_fill.ipynb#W4sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m patient \u001b[39m=\u001b[39m path[:\u001b[39m-\u001b[39m\u001b[39m4\u001b[39m]\n\u001b[1;32m---> <a href='vscode-notebook-cell:/e%3A/LUNA/Lung_segmentation/Res_BCDU_net_hole_fill.ipynb#W4sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m final \u001b[39m=\u001b[39m run_segmentation(te_data_copy)\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/LUNA/Lung_segmentation/Res_BCDU_net_hole_fill.ipynb#W4sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m \u001b[39m# run_segmentation(te_data, row, 0, patient, ax)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/LUNA/Lung_segmentation/Res_BCDU_net_hole_fill.ipynb#W4sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m \u001b[39mprint\u001b[39m(final\u001b[39m.\u001b[39mshape)\n",
      "\u001b[1;32me:\\LUNA\\Lung_segmentation\\Res_BCDU_net_hole_fill.ipynb Cell 5\u001b[0m line \u001b[0;36mrun_segmentation\u001b[1;34m(te_data)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/LUNA/Lung_segmentation/Res_BCDU_net_hole_fill.ipynb#W4sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m model \u001b[39m=\u001b[39m BCDUNet(input_dim, output_dim, num_filter, frame_size, bidirectional, norm)\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/LUNA/Lung_segmentation/Res_BCDU_net_hole_fill.ipynb#W4sZmlsZQ%3D%3D?line=52'>53</a>\u001b[0m model\u001b[39m.\u001b[39mload_state_dict(torch\u001b[39m.\u001b[39mload(\u001b[39m'\u001b[39m\u001b[39mmodel.pth\u001b[39m\u001b[39m'\u001b[39m, map_location\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mdevice(\u001b[39m\"\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m\"\u001b[39m)))\n\u001b[1;32m---> <a href='vscode-notebook-cell:/e%3A/LUNA/Lung_segmentation/Res_BCDU_net_hole_fill.ipynb#W4sZmlsZQ%3D%3D?line=53'>54</a>\u001b[0m predictions \u001b[39m=\u001b[39m predict(test_loader, model, device) \n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/LUNA/Lung_segmentation/Res_BCDU_net_hole_fill.ipynb#W4sZmlsZQ%3D%3D?line=54'>55</a>\u001b[0m \u001b[39m# print(\"Predict ends\")\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/LUNA/Lung_segmentation/Res_BCDU_net_hole_fill.ipynb#W4sZmlsZQ%3D%3D?line=55'>56</a>\u001b[0m \n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/LUNA/Lung_segmentation/Res_BCDU_net_hole_fill.ipynb#W4sZmlsZQ%3D%3D?line=56'>57</a>\u001b[0m \u001b[39m# Post-processing\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/LUNA/Lung_segmentation/Res_BCDU_net_hole_fill.ipynb#W4sZmlsZQ%3D%3D?line=57'>58</a>\u001b[0m predictions \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39msqueeze(predictions)\n",
      "\u001b[1;32me:\\LUNA\\Lung_segmentation\\Res_BCDU_net_hole_fill.ipynb Cell 5\u001b[0m line \u001b[0;36mrun_segmentation.<locals>.predict\u001b[1;34m(test_loader, model, device)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/LUNA/Lung_segmentation/Res_BCDU_net_hole_fill.ipynb#W4sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m x \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mto(device)                        \n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/LUNA/Lung_segmentation/Res_BCDU_net_hole_fill.ipynb#W4sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():                   \n\u001b[1;32m---> <a href='vscode-notebook-cell:/e%3A/LUNA/Lung_segmentation/Res_BCDU_net_hole_fill.ipynb#W4sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m     pred \u001b[39m=\u001b[39m model(x)                     \n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/LUNA/Lung_segmentation/Res_BCDU_net_hole_fill.ipynb#W4sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m     preds\u001b[39m.\u001b[39mappend(pred\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mcpu())   \n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/LUNA/Lung_segmentation/Res_BCDU_net_hole_fill.ipynb#W4sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m     pbar\u001b[39m.\u001b[39mupdate(\u001b[39m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\oplab\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32me:\\LUNA\\Lung_segmentation\\Res_BCDU_net_hole_fill.ipynb Cell 5\u001b[0m line \u001b[0;36mBCDUNet.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    <a href='vscode-notebook-cell:/e%3A/LUNA/Lung_segmentation/Res_BCDU_net_hole_fill.ipynb#W4sZmlsZQ%3D%3D?line=271'>272</a>\u001b[0m concat3 \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat((concat3, concat3), \u001b[39m1\u001b[39m)\n\u001b[0;32m    <a href='vscode-notebook-cell:/e%3A/LUNA/Lung_segmentation/Res_BCDU_net_hole_fill.ipynb#W4sZmlsZQ%3D%3D?line=272'>273</a>\u001b[0m concat3 \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat((conv3, concat3), \u001b[39m1\u001b[39m)\n\u001b[1;32m--> <a href='vscode-notebook-cell:/e%3A/LUNA/Lung_segmentation/Res_BCDU_net_hole_fill.ipynb#W4sZmlsZQ%3D%3D?line=273'>274</a>\u001b[0m conv3m \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconv3m(concat3)\n\u001b[0;32m    <a href='vscode-notebook-cell:/e%3A/LUNA/Lung_segmentation/Res_BCDU_net_hole_fill.ipynb#W4sZmlsZQ%3D%3D?line=274'>275</a>\u001b[0m conv3m \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrelu(conv3m)\n\u001b[0;32m    <a href='vscode-notebook-cell:/e%3A/LUNA/Lung_segmentation/Res_BCDU_net_hole_fill.ipynb#W4sZmlsZQ%3D%3D?line=276'>277</a>\u001b[0m upconv2 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mupconv2(conv3m)\n",
      "File \u001b[1;32mc:\\Users\\oplab\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\oplab\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\container.py:204\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    202\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[0;32m    203\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[1;32m--> 204\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[0;32m    205\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\oplab\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\oplab\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py:463\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    462\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 463\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[1;32mc:\\Users\\oplab\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py:459\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m    456\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv2d(F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode),\n\u001b[0;32m    457\u001b[0m                     weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[0;32m    458\u001b[0m                     _pair(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[1;32m--> 459\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv2d(\u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[0;32m    460\u001b[0m                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "####################################  Load Data #####################################\n",
    "# root = \"E:\\LUNA\\Interpolation\\Luna1\\image\\subset0/\"\n",
    "root = \"../Luna16_AugData/subset0/\"\n",
    "write_root = \"./seg_result/\"\n",
    "# root2 = \"./yolo/\"\n",
    "for e, path in enumerate(os.listdir(root)):\n",
    "    if path.find(\"mhd\") >= 0 and e > 1:\n",
    "        try:\n",
    "            print(int(e/2), path)\n",
    "\n",
    "            te_data = sitk.ReadImage(os.path.join(root, path))\n",
    "            te_data = sitk.GetArrayFromImage(te_data)\n",
    "            # num_random_indexes = 2\n",
    "            # random_indices = random.sample(range(len(te_data)), num_random_indexes)\n",
    "            # print(random_indices)\n",
    "            te_data = te_data\n",
    "            te_data_copy = copy.deepcopy(te_data)\n",
    "            # print(te_data[0:2].shape)\n",
    "            # continue\n",
    "            te_data[te_data < -1000] = -1000\n",
    "            te_data[te_data > -500] = 0\n",
    "            # te_data_copy[te_data_copy < -1000] = -1000\n",
    "            # te_data_copy[te_data_copy > 1000] = 1000\n",
    "            # Sample results\n",
    "            from sklearn.metrics import mean_squared_error\n",
    "            # amount = len(te_data) + len(te_data_copy)\n",
    "            amount = len(te_data)\n",
    "            # row = int(e/2)\n",
    "            patient = path[:-4]\n",
    "            final = run_segmentation(te_data_copy)\n",
    "            # run_segmentation(te_data, row, 0, patient, ax)\n",
    "            print(final.shape)\n",
    "            # run_segmentation(te_data, row, 0, patient, ax)\n",
    "            # Load or create a SimpleITK image\n",
    "            current_image = sitk.ReadImage(os.path.join(root, path))  # Replace with the path to your image\n",
    "\n",
    "            current_origin = current_image.GetOrigin()\n",
    "            current_spacing = current_image.GetSpacing()\n",
    "\n",
    "            # final: 3D np array, converted into .raw\n",
    "            sitk_image = sitk.GetImageFromArray(final)\n",
    "            # image_short = sitk.Cast(image, sitk.sitkInt16)\n",
    "\n",
    "            # Set the image origin, spacing, and direction (modify as needed)\n",
    "            sitk_image.SetOrigin((current_origin[0], current_origin[1], current_origin[2]))\n",
    "            sitk_image.SetSpacing((current_spacing[0], current_spacing[1], current_spacing[2]))\n",
    "\n",
    "            # Save the image as a MetaImage file\n",
    "            # if not os.path.exists(os.path.join(write_root, path)):\n",
    "            #     os.mkdir(os.path.join(write_root, path))\n",
    "            sitk.WriteImage(sitk_image, os.path.join(write_root, path)) \n",
    "            print(\"Saved\\n=============\")\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            continue\n",
    "# for e, path in enumerate(os.listdir(root2)):\n",
    "#     if path.find(\"origin\") >= 0 and e < 10:\n",
    "#         print(e, path)\n",
    "#         te_data = iio.imread(os.path.join(root2, path))\n",
    "#         te_data = np.array(te_data)\n",
    "#         # print(te_data.shape)\n",
    "#         # te_data[te_data < -1000] = -1000\n",
    "#         # te_data[te_data > -500] = 0\n",
    "#         patient, num, malignancy_str = path.split(\"_\")[1], path.split(\"_\")[2], path.split(\"_\")[3]\n",
    "#         malignancy = True if malignancy_str[:-4] == \"True\" else False\n",
    "#         run_segmentation_yolo_annotate(te_data, patient, num, malignancy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import SimpleITK as sitk\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "# test\n",
    "root3 = \"./seg_result/\"\n",
    "for e, path in enumerate(os.listdir(root3)):\n",
    "    if path.find(\"mhd\") >= 0 and e <= 5:\n",
    "        try:\n",
    "            print(int(e/2), path)\n",
    "            te_data = sitk.ReadImage(os.path.join(root3, path))\n",
    "            te_data = sitk.GetArrayFromImage(te_data)\n",
    "            # te_data[te_data < -1000] += \n",
    "            # te_data[te_data > 1000] = 1000\n",
    "            print(te_data.shape)\n",
    "            pbar = tqdm(total=len(te_data))\n",
    "            for i in range(int(len(te_data)/10)+1):\n",
    "                fig, ax = plt.subplots(1, 10, figsize=[40, 4])\n",
    "                for j in range(10):\n",
    "                    # print(i*10+j)\n",
    "                    # unique, counts = np.unique(te_data[i], return_counts=True)\n",
    "                    # print(dict(zip(unique, counts)))\n",
    "                    try:\n",
    "                        ax[j].imshow(np.squeeze(te_data[i*10+j]), cmap='gray')\n",
    "                        pbar.update(1)\n",
    "                    except Exception as e:\n",
    "                        print(e)\n",
    "                        break\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
