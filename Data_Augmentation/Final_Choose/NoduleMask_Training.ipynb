{"cells":[{"cell_type":"markdown","metadata":{"id":"jRDuJsGCgxCO","tags":[]},"source":["## Data Augmentation"]},{"cell_type":"markdown","metadata":{"id":"K9Vxu1iQwdIE"},"source":["### Check GPU Type"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1700618288962,"user":{"displayName":"劉惟恩","userId":"02074838684670325178"},"user_tz":-480},"id":"KKjf6sZcwb_A","outputId":"3c968ca3-8885-4151-9c00-c0ee586cde83","tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Thu Nov 30 17:21:11 2023       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 528.24       Driver Version: 528.24       CUDA Version: 12.0     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  NVIDIA GeForce ... WDDM  | 00000000:01:00.0  On |                  Off |\n","|  0%   42C    P8    11W / 450W |    369MiB / 24564MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|    0   N/A  N/A      9232    C+G   C:\\Windows\\explorer.exe         N/A      |\n","|    0   N/A  N/A      9248    C+G   ...ge\\Application\\msedge.exe    N/A      |\n","|    0   N/A  N/A     10464    C+G   ...n1h2txyewy\\SearchHost.exe    N/A      |\n","|    0   N/A  N/A     10488    C+G   ...artMenuExperienceHost.exe    N/A      |\n","|    0   N/A  N/A     11684    C+G   ...y\\ShellExperienceHost.exe    N/A      |\n","|    0   N/A  N/A     12580    C+G   ...2txyewy\\TextInputHost.exe    N/A      |\n","|    0   N/A  N/A     16492    C+G   ...oft\\OneDrive\\OneDrive.exe    N/A      |\n","+-----------------------------------------------------------------------------+\n"]}],"source":["!nvidia-smi"]},{"cell_type":"markdown","metadata":{"id":"n5ceUnRihL-f"},"source":["### Import Packages"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ay3WkYnHVaVE","tags":[]},"outputs":[],"source":["_exp_name = \"NoduleMask\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CwOGtRWHVaVF","tags":[]},"outputs":[],"source":["# Import necessary packages.\n","import numpy as np\n","import pandas as pd\n","import torch\n","import os\n","import torch.nn as nn\n","import torchvision.transforms as transforms\n","from PIL import Image\n","# \"ConcatDataset\" and \"Subset\" are possibly useful when doing semi-supervised learning.\n","from torch.utils.data import ConcatDataset, DataLoader, Subset, Dataset\n","from torchvision.datasets import DatasetFolder, VisionDataset\n","# This is for the progress bar.\n","from tqdm.auto import tqdm\n","import random\n","from random import shuffle\n","\n","# cache\n","from functools import lru_cache"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"8kJm9GekVaVH","tags":[]},"outputs":[],"source":["myseed = 6666  # set a random seed for reproducibility\n","torch.backends.cudnn.deterministic = True\n","torch.backends.cudnn.benchmark = False\n","#This flag allows you to enable the inbuilt cudnn auto-tuner to find the best algorithm to use for your hardware.\n","np.random.seed(myseed)\n","torch.manual_seed(myseed)\n","if torch.cuda.is_available():\n","    torch.cuda.manual_seed_all(myseed)"]},{"cell_type":"markdown","metadata":{"id":"D0ivMf-jVaVK"},"source":["### Datasets"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"xBdtPhKwVaVL","tags":[]},"outputs":[],"source":["class DADataset(Dataset):\n","    def __init__(self, path, part, files=None):\n","        super(DADataset, self).__init__()\n","        self.path = path\n","        self.files = sorted([os.path.join(path, x) for x in os.listdir(path)])\n","        random.seed(8)  # Use random.seed to ensure reproducibility\n","        random.shuffle(self.files)\n","        total_files = len(self.files)\n","        cutTrain = total_files // 10 * 8\n","        cutTest = int(len(self.files) // 10 * 9)\n","        if part == \"train\":\n","            self.files = self.files[:cutTrain]\n","        elif part == \"val\":\n","            self.files = self.files[cutTrain:cutTest]\n","        elif part == \"test\":\n","            self.files = self.files[cutTest:]\n","        else:\n","            raise ValueError(\"Invalid part. Must be 'train', 'val', or 'test'.\")\n","        if files is not None:\n","            self.files = files\n","\n","    def __len__(self):\n","        return len(self.files)\n","\n","    def __getitem__(self, idx):\n","        fname = self.files[idx]\n","\n","        # Split the string using the underscore as a delimiter\n","        pid = fname.split(\"\\\\\")[-1].split(\"_\")[-2]\n","        slice_num = int(fname.split(\"\\\\\")[-1].split(\"_\")[-1])\n","        im = torch.from_numpy(np.load(fname + \"/train_mask.npy\")).float()\n","        label = torch.from_numpy(np.load(fname + \"/val_mask.npy\")).float()\n","\n","        return pid, slice_num, im, label"]},{"cell_type":"markdown","metadata":{"id":"ZPFkDwug61PZ"},"source":["### Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"b8HvbFoxzsaI"},"outputs":[],"source":["class UNet(nn.Module):\n","    def __init__(self):\n","        super(UNet, self).__init__()\n","        self.down_conv1 = self.double_conv(4, 64)\n","        self.down_conv2 = self.double_conv(64, 128)\n","        self.down_conv3 = self.double_conv(128, 256)\n","        self.down_conv4 = self.double_conv(256, 512)\n","        self.up_conv1 = self.double_conv(512 + 256, 256)\n","        self.up_conv2 = self.double_conv(256 + 128, 128)\n","        self.up_conv3 = self.double_conv(128 + 64, 64)\n","        self.up_conv4 = nn.Conv2d(64, 1, kernel_size=1)\n","        self.maxpool = nn.MaxPool2d(2)\n","        self.upsample = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n","\n","    def double_conv(self, in_channels, out_channels):\n","        return nn.Sequential(\n","            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n","            nn.ReLU(inplace=True)\n","        )\n","\n","    def forward(self, x):\n","        # Downward path\n","        x1 = self.down_conv1(x)\n","        x2 = self.maxpool(x1)\n","        x3 = self.down_conv2(x2)\n","        x4 = self.maxpool(x3)\n","        x5 = self.down_conv3(x4)\n","        x6 = self.maxpool(x5)\n","        x7 = self.down_conv4(x6)\n","\n","        # Upward path\n","        x = self.upsample(x7)\n","        x = torch.cat([x, x5], dim=1)\n","        x = self.up_conv1(x)\n","        x = self.upsample(x)\n","        x = torch.cat([x, x3], dim=1)\n","        x = self.up_conv2(x)\n","        x = self.upsample(x)\n","        x = torch.cat([x, x1], dim=1)\n","        x = self.up_conv3(x)\n","        x = self.up_conv4(x)\n","\n","        return x"]},{"cell_type":"raw","metadata":{"id":"b_kDECOJVaVL","tags":[]},"source":["import torch\n","import torch.nn as nn\n","\n","class UNet(nn.Module):\n","    def __init__(self):\n","        super(UNet, self).__init__()\n","        self.down_conv1 = self.double_conv(4, 64)\n","        self.down_conv2 = self.double_conv(64, 128)\n","        self.down_conv3 = self.double_conv(128, 256)\n","        self.down_conv4 = self.double_conv(256, 512)\n","        self.up_conv1 = self.double_conv(512 + 256, 256)\n","        self.up_conv2 = self.double_conv(256 + 128, 128)\n","        self.up_conv3 = self.double_conv(128 + 64, 64)\n","        self.up_conv4 = nn.Conv2d(64, 1, kernel_size=1)\n","        self.maxpool = nn.MaxPool2d(2)\n","        self.upsample = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n","\n","    def double_conv(self, in_channels, out_channels):\n","        return nn.Sequential(\n","            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n","            nn.ReLU(inplace=True)\n","        )\n","\n","    def forward(self, x):\n","        # Downward path\n","        x1 = self.down_conv1(x)\n","        x2 = self.maxpool(x1)\n","        x3 = self.down_conv2(x2)\n","        x4 = self.maxpool(x3)\n","        x5 = self.down_conv3(x4)\n","        x6 = self.maxpool(x5)\n","        x7 = self.down_conv4(x6)\n","\n","        # Upward path\n","        x = self.upsample(x7)\n","        x = torch.cat([x, x5], dim=1)\n","        x = self.up_conv1(x)\n","        x = self.upsample(x)\n","        x = torch.cat([x, x3], dim=1)\n","        x = self.up_conv2(x)\n","        x = self.upsample(x)\n","        x = torch.cat([x, x1], dim=1)\n","        x = self.up_conv3(x)\n","\n","        # Apply sigmoid activation to the last layer\n","        x = nn.Sigmoid()(self.up_conv4(x))\n","\n","        return x"]},{"cell_type":"markdown","metadata":{"id":"xgnIOaID687b"},"source":["### Configurations"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"2_OeWtstVaVO","tags":[]},"outputs":[],"source":["# \"cuda\" only when GPUs are available.\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# Initialize a model and put it on the specified device.\n","model = UNet().to(device)\n","\n","# The number of batch size.\n","batch_size = 10\n","\n","# The number of training epochs.\n","n_epochs = 100\n","\n","# If no improvement in 'patience' epochs, early stop.\n","patience = 10\n","\n","# For the classification task, we use mean squared error as the measurement of performance.\n","criterion = nn.MSELoss()\n","\n","# Initialize optimizer. You may fine-tune some hyperparameters such as learning rate on your own.\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)"]},{"cell_type":"markdown","metadata":{"id":"zPGwvvPK7F7u"},"source":["### Dataloader"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"zvZXRH2phItl","tags":[]},"outputs":[],"source":["# Construct train and valid datasets.\n","# The argument \"loader\" tells how torchvision reads the data.\n","@lru_cache(maxsize=None)  # None means cache all results\n","def get_dataset_loader(path, part, batch_size, shuffle=True):\n","    dataset = DADataset(path, part)\n","    loader = DataLoader(dataset, batch_size=batch_size, shuffle=shuffle, num_workers=0, pin_memory=True)\n","    return loader\n","\n","# ... (The rest of your code remains the same)\n","\n","# Construct train and valid datasets using the caching function.\n","train_loader = get_dataset_loader(\"../Luna16_data/split4_mask_data_nodule\", \"train\", batch_size=batch_size)\n","valid_loader = get_dataset_loader(\"../Luna16_data/split4_mask_data_nodule\", \"val\", batch_size=batch_size)"]},{"cell_type":"markdown","metadata":{"id":"UPQ0j1c17BG1"},"source":["### Start Training"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"referenced_widgets":["ec1520c0de8f48e0832e0f2b19ccaf99","d1d847091868420ab268f82f4dcad293","4d40971e5b2d44038a3fec0191c513f8","ab007f8148b44aa39bba497b3236a29e","f2977f4410664fa9a01ebd931c8c51ae","80f7f92b20ad48cdb5de50208cdbfa3f","18100c2f021f4322b3901e6aa8b78f51","ed6da8a7751d4bb5a9f344be10586983","c93c145c41be45cb944a07944b826bcf","d2aef5cbf8024013b77c948195308cc8","e210c531555c49feba6dfd6b27c531b0","173ea6ca5f6b41e9bdf6ce1ba38c57e6","dd7798260ed745509b3a7f42a4055b9d","a1b3a06838294a828df0e394ace224fa","940014e9f4e8491bae5088a326134fec","4f1ab36523aa450385aaf572e69227fc","73807187703246dc80785eb4cf6fe317","9099de47733c4eceba170337c9a93032","841496decf914b94b9f911cdf90d465e","68f30efa872242428c53e1bb8ba740fc","76623f1cf67d474d832cd6d8a2ac197c"]},"id":"zbVkfIFhVaVO","outputId":"4d4eb113-adfa-4fb0-eb02-7c6be3f16938","tags":[]},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"76623f1cf67d474d832cd6d8a2ac197c","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/675 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["torch.Size([512, 512])\n","torch.Size([4, 512, 512])\n","torch.Size([512, 512])\n","torch.Size([4, 512, 512])\n","torch.Size([512, 512])\n","torch.Size([4, 512, 512])\n","torch.Size([512, 512])\n","torch.Size([4, 512, 512])\n","torch.Size([512, 512])\n","torch.Size([4, 512, 512])\n","torch.Size([512, 512])\n","torch.Size([4, 512, 512])\n","torch.Size([512, 512])\n","torch.Size([4, 512, 512])\n","torch.Size([512, 512])\n","torch.Size([4, 512, 512])\n","torch.Size([512, 512])\n","torch.Size([4, 512, 512])\n","torch.Size([512, 512])\n","torch.Size([4, 512, 512])\n","torch.Size([512, 512])\n","torch.Size([4, 512, 512])\n","torch.Size([512, 512])\n","torch.Size([4, 512, 512])\n","torch.Size([512, 512])\n","torch.Size([4, 512, 512])\n","torch.Size([512, 512])\n","torch.Size([4, 512, 512])\n","torch.Size([512, 512])\n","torch.Size([4, 512, 512])\n","torch.Size([512, 512])\n","torch.Size([4, 512, 512])\n","torch.Size([512, 512])\n","torch.Size([4, 512, 512])\n","torch.Size([512, 512])\n","torch.Size([4, 512, 512])\n","torch.Size([512, 512])\n","torch.Size([4, 512, 512])\n","torch.Size([512, 512])\n","torch.Size([4, 512, 512])\n","torch.Size([512, 512])\n","torch.Size([4, 512, 512])\n","torch.Size([512, 512])\n","torch.Size([4, 512, 512])\n","torch.Size([512, 512])\n","torch.Size([4, 512, 512])\n","torch.Size([512, 512])\n","torch.Size([4, 512, 512])\n","torch.Size([512, 512])\n","torch.Size([4, 512, 512])\n","torch.Size([512, 512])\n","torch.Size([4, 512, 512])\n","torch.Size([512, 512])\n","torch.Size([4, 512, 512])\n","torch.Size([512, 512])\n","torch.Size([4, 512, 512])\n","torch.Size([512, 512])\n","torch.Size([4, 512, 512])\n","torch.Size([512, 512])\n","torch.Size([4, 512, 512])\n","torch.Size([512, 512])\n","torch.Size([4, 512, 512])\n","torch.Size([512, 512])\n","torch.Size([4, 512, 512])\n","torch.Size([512, 512])\n","torch.Size([4, 512, 512])\n","torch.Size([512, 512])\n","torch.Size([4, 512, 512])\n","torch.Size([512, 512])\n","torch.Size([4, 512, 512])\n","torch.Size([512, 512])\n","torch.Size([4, 512, 512])\n","torch.Size([512, 512])\n","torch.Size([4, 512, 512])\n","torch.Size([512, 512])\n","torch.Size([4, 512, 512])\n","torch.Size([512, 512])\n","torch.Size([4, 512, 512])\n","torch.Size([512, 512])\n","torch.Size([4, 512, 512])\n","torch.Size([512, 512])\n","torch.Size([4, 512, 512])\n","torch.Size([512, 512])\n","torch.Size([4, 512, 512])\n","torch.Size([512, 512])\n","torch.Size([4, 512, 512])\n","torch.Size([512, 512])\n","torch.Size([4, 512, 512])\n","torch.Size([512, 512])\n","torch.Size([4, 512, 512])\n","torch.Size([512, 512])\n","torch.Size([4, 512, 512])\n","torch.Size([512, 512])\n","torch.Size([4, 512, 512])\n","torch.Size([512, 512])\n","torch.Size([4, 512, 512])\n","torch.Size([512, 512])\n","torch.Size([4, 512, 512])\n","torch.Size([512, 512])\n","torch.Size([4, 512, 512])\n","torch.Size([512, 512])\n","torch.Size([4, 512, 512])\n","torch.Size([512, 512])\n","torch.Size([4, 512, 512])\n","torch.Size([512, 512])\n","torch.Size([4, 512, 512])\n","torch.Size([512, 512])\n","torch.Size([4, 512, 512])\n","torch.Size([512, 512])\n","torch.Size([4, 512, 512])\n","torch.Size([512, 512])\n","torch.Size([4, 512, 512])\n","torch.Size([512, 512])\n","torch.Size([4, 512, 512])\n","torch.Size([512, 512])\n","torch.Size([4, 512, 512])\n","torch.Size([512, 512])\n","torch.Size([4, 512, 512])\n","torch.Size([512, 512])\n","torch.Size([4, 512, 512])\n","torch.Size([512, 512])\n","torch.Size([4, 512, 512])\n","torch.Size([512, 512])\n","torch.Size([4, 512, 512])\n","torch.Size([512, 512])\n","torch.Size([4, 512, 512])\n","torch.Size([512, 512])\n","torch.Size([4, 512, 512])\n","torch.Size([512, 512])\n","torch.Size([4, 512, 512])\n","torch.Size([512, 512])\n","torch.Size([4, 512, 512])\n","torch.Size([512, 512])\n","torch.Size([4, 512, 512])\n","torch.Size([512, 512])\n","torch.Size([4, 512, 512])\n","torch.Size([512, 512])\n","torch.Size([4, 512, 512])\n","torch.Size([512, 512])\n","torch.Size([4, 512, 512])\n","torch.Size([512, 512])\n","torch.Size([4, 512, 512])\n","torch.Size([512, 512])\n","torch.Size([4, 512, 512])\n","torch.Size([512, 512])\n","torch.Size([4, 512, 512])\n","torch.Size([512, 512])\n","torch.Size([4, 512, 512])\n","torch.Size([512, 512])\n","torch.Size([4, 512, 512])\n","torch.Size([512, 512])\n","torch.Size([4, 512, 512])\n","torch.Size([512, 512])\n","torch.Size([4, 512, 512])\n","torch.Size([512, 512])\n","torch.Size([4, 512, 512])\n","torch.Size([512, 512])\n","torch.Size([4, 512, 512])\n","torch.Size([512, 512])\n","torch.Size([4, 512, 512])\n","torch.Size([512, 512])\n","torch.Size([4, 512, 512])\n","torch.Size([512, 512])\n","torch.Size([4, 512, 512])\n","torch.Size([512, 512])\n","torch.Size([4, 512, 512])\n","torch.Size([512, 512])\n","torch.Size([4, 512, 512])\n","torch.Size([512, 512])\n","torch.Size([4, 512, 512])\n","torch.Size([512, 512])\n","torch.Size([4, 512, 512])\n","torch.Size([512, 512])\n","torch.Size([4, 512, 512])\n","torch.Size([512, 512])\n","torch.Size([4, 512, 512])\n","torch.Size([512, 512])\n","torch.Size([4, 512, 512])\n","torch.Size([512, 512])\n","torch.Size([4, 512, 512])\n","torch.Size([512, 512])\n","torch.Size([4, 512, 512])\n","torch.Size([512, 512])\n","torch.Size([4, 512, 512])\n","torch.Size([512, 512])\n","torch.Size([4, 512, 512])\n","torch.Size([512, 512])\n","torch.Size([4, 512, 512])\n","torch.Size([512, 512])\n","torch.Size([4, 512, 512])\n","torch.Size([512, 512])\n","torch.Size([4, 512, 512])\n","torch.Size([512, 512])\n","torch.Size([4, 512, 512])\n","torch.Size([512, 512])\n","torch.Size([4, 512, 512])\n","torch.Size([512, 512])\n","torch.Size([4, 512, 512])\n","torch.Size([512, 512])\n","torch.Size([4, 512, 512])\n","torch.Size([512, 512])\n","torch.Size([4, 512, 512])\n","torch.Size([512, 512])\n","torch.Size([4, 512, 512])\n","torch.Size([512, 512])\n","torch.Size([4, 512, 512])\n","torch.Size([512, 512])\n","torch.Size([4, 512, 512])\n","torch.Size([512, 512])\n","torch.Size([4, 512, 512])\n","torch.Size([512, 512])\n","torch.Size([4, 512, 512])\n","torch.Size([512, 512])\n","torch.Size([4, 512, 512])\n","torch.Size([512, 512])\n","torch.Size([4, 512, 512])\n","torch.Size([512, 512])\n","torch.Size([4, 512, 512])\n","torch.Size([512, 512])\n","torch.Size([4, 512, 512])\n","torch.Size([512, 512])\n","torch.Size([4, 512, 512])\n","torch.Size([512, 512])\n","torch.Size([4, 512, 512])\n","torch.Size([512, 512])\n","torch.Size([4, 512, 512])\n","torch.Size([512, 512])\n","torch.Size([4, 512, 512])\n","torch.Size([512, 512])\n","torch.Size([4, 512, 512])\n","torch.Size([512, 512])\n","torch.Size([4, 512, 512])\n","torch.Size([512, 512])\n","torch.Size([4, 512, 512])\n","torch.Size([512, 512])\n","torch.Size([4, 512, 512])\n","torch.Size([512, 512])\n","torch.Size([4, 512, 512])\n","torch.Size([512, 512])\n","torch.Size([4, 512, 512])\n","torch.Size([512, 512])\n","torch.Size([4, 512, 512])\n","torch.Size([512, 512])\n","torch.Size([4, 512, 512])\n","torch.Size([512, 512])\n","torch.Size([4, 512, 512])\n","torch.Size([512, 512])\n","torch.Size([4, 512, 512])\n","torch.Size([512, 512])\n","torch.Size([4, 512, 512])\n","torch.Size([512, 512])\n","torch.Size([4, 512, 512])\n","torch.Size([512, 512])\n","torch.Size([4, 512, 512])\n","torch.Size([512, 512])\n","torch.Size([4, 512, 512])\n","torch.Size([512, 512])\n","torch.Size([4, 512, 512])\n","torch.Size([512, 512])\n","torch.Size([4, 512, 512])\n","torch.Size([512, 512])\n","torch.Size([4, 512, 512])\n","torch.Size([512, 512])\n","torch.Size([4, 512, 512])\n","torch.Size([512, 512])\n","torch.Size([4, 512, 512])\n","torch.Size([512, 512])\n","torch.Size([4, 512, 512])\n","torch.Size([512, 512])\n","torch.Size([4, 512, 512])\n","torch.Size([512, 512])\n","torch.Size([4, 512, 512])\n","torch.Size([512, 512])\n","torch.Size([4, 512, 512])\n","torch.Size([512, 512])\n","torch.Size([4, 512, 512])\n","torch.Size([512, 512])\n","torch.Size([4, 512, 512])\n","torch.Size([512, 512])\n","torch.Size([4, 512, 512])\n","torch.Size([512, 512])\n","torch.Size([4, 512, 512])\n","torch.Size([512, 512])\n","torch.Size([4, 512, 512])\n","torch.Size([512, 512])\n","torch.Size([4, 512, 512])\n","torch.Size([512, 512])\n","torch.Size([4, 512, 512])\n","torch.Size([512, 512])\n","torch.Size([4, 512, 512])\n","torch.Size([512, 512])\n","torch.Size([4, 512, 512])\n","torch.Size([512, 512])\n","torch.Size([4, 512, 512])\n","torch.Size([512, 512])\n","torch.Size([4, 512, 512])\n","torch.Size([512, 512])\n","torch.Size([4, 512, 512])\n","torch.Size([512, 512])\n","torch.Size([4, 512, 512])\n","torch.Size([512, 512])\n","torch.Size([4, 512, 512])\n","torch.Size([512, 512])\n","torch.Size([4, 512, 512])\n","torch.Size([512, 512])\n","torch.Size([4, 512, 512])\n","torch.Size([512, 512])\n","torch.Size([4, 512, 512])\n","torch.Size([512, 512])\n","torch.Size([4, 512, 512])\n","torch.Size([512, 512])\n","torch.Size([4, 512, 512])\n","torch.Size([512, 512])\n","torch.Size([4, 512, 512])\n","torch.Size([512, 512])\n","torch.Size([4, 512, 512])\n","torch.Size([512, 512])\n","torch.Size([4, 512, 512])\n","torch.Size([512, 512])\n","torch.Size([4, 512, 512])\n","torch.Size([512, 512])\n","torch.Size([4, 512, 512])\n","torch.Size([512, 512])\n","torch.Size([4, 512, 512])\n","torch.Size([512, 512])\n","torch.Size([4, 512, 512])\n","torch.Size([512, 512])\n","torch.Size([4, 512, 512])\n","torch.Size([512, 512])\n","torch.Size([4, 512, 512])\n","torch.Size([512, 512])\n","torch.Size([4, 512, 512])\n","torch.Size([512, 512])\n","torch.Size([4, 512, 512])\n","torch.Size([512, 512])\n","torch.Size([4, 512, 512])\n","torch.Size([512, 512])\n","torch.Size([4, 512, 512])\n","torch.Size([512, 512])\n","torch.Size([4, 512, 512])\n","torch.Size([512, 512])\n","torch.Size([4, 512, 512])\n","torch.Size([512, 512])\n","torch.Size([4, 512, 512])\n","torch.Size([512, 512])\n","torch.Size([4, 512, 512])\n","torch.Size([512, 512])\n","torch.Size([4, 512, 512])\n","torch.Size([512, 512])\n","torch.Size([4, 512, 512])\n","torch.Size([512, 512])\n","torch.Size([4, 512, 512])\n","torch.Size([512, 512])\n","torch.Size([4, 512, 512])\n","torch.Size([512, 512])\n","torch.Size([4, 512, 512])\n","torch.Size([512, 512])\n","torch.Size([4, 512, 512])\n","torch.Size([512, 512])\n","torch.Size([4, 512, 512])\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[1;32mIn[10], line 34\u001b[0m\n\u001b[0;32m     31\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# Clip the gradient norms for stable training.\u001b[39;00m\n\u001b[1;32m---> 34\u001b[0m grad_norm \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(model\u001b[38;5;241m.\u001b[39mparameters(), max_norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m# Update the parameters with computed gradients.\u001b[39;00m\n\u001b[0;32m     37\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n","File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\utils\\clip_grad.py:76\u001b[0m, in \u001b[0;36mclip_grad_norm_\u001b[1;34m(parameters, max_norm, norm_type, error_if_nonfinite, foreach)\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ((device, _), [grads]) \u001b[38;5;129;01min\u001b[39;00m grouped_grads\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (foreach \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m foreach) \u001b[38;5;129;01mand\u001b[39;00m _has_foreach_support(grads, device\u001b[38;5;241m=\u001b[39mdevice):\n\u001b[1;32m---> 76\u001b[0m         torch\u001b[38;5;241m.\u001b[39m_foreach_mul_(grads, clip_coef_clamped\u001b[38;5;241m.\u001b[39mto(device))  \u001b[38;5;66;03m# type: ignore[call-overload]\u001b[39;00m\n\u001b[0;32m     77\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m foreach:\n\u001b[0;32m     78\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mforeach=True was passed, but can\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124mt use the foreach API on \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdevice\u001b[38;5;241m.\u001b[39mtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m tensors\u001b[39m\u001b[38;5;124m'\u001b[39m)\n","\u001b[1;31mKeyboardInterrupt\u001b[0m: "]}],"source":["# Initialize trackers, these are not parameters and should not be changed\n","stale = 0\n","best_loss = float('inf')\n","\n","for epoch in range(n_epochs):\n","    # ---------- Training ----------\n","    # Make sure the model is in train mode before training.\n","    model.train()\n","\n","    # These are used to record information in training.\n","    train_loss = []\n","    # train_accs = []\n","\n","    for batch in tqdm(train_loader):\n","        # A batch consists of image data and corresponding labels.\n","        pid, slice_num, imgs, labels = batch\n","\n","        # Forward the data. (Make sure data and model are on the same device.)\n","        images = imgs.to(device)\n","\n","        # Forward pass\n","        logits = model(images)\n","\n","        # Calculate the loss\n","        loss = criterion(logits.view(-1, 512*512), labels.view(-1, 512*512).to(device))  # Calculate the loss\n","\n","        # Gradients stored in the parameters in the previous step should be cleared out first.\n","        optimizer.zero_grad()\n","\n","        # Compute the gradients for parameters.\n","        loss.backward()\n","\n","        # Clip the gradient norms for stable training.\n","        grad_norm = nn.utils.clip_grad_norm_(model.parameters(), max_norm=10)\n","\n","        # Update the parameters with computed gradients.\n","        optimizer.step()\n","\n","        # Compute the accuracy for the current batch.\n","        # acc = (logits.argmax(dim=-1) == labels.to(device)).float().mean()\n","\n","        # Record the loss and accuracy.\n","        train_loss.append(loss.item())\n","        # train_accs.append(acc.item())\n","\n","    train_loss = sum(train_loss) / len(train_loss)\n","    # train_acc = sum(train_accs) / len(train_accs)\n","\n","    # Print the information.\n","    print(f\"[ Train | {epoch + 1:03d}/{n_epochs:03d} ] loss = {train_loss:.5f}\")\n","\n","    # ---------- Validation ----------\n","    # Make sure the model is in eval mode so that some modules like dropout are disabled and work normally.\n","    model.eval()\n","\n","    # These are used to record information in validation.\n","    valid_loss = []\n","    # valid_accs = []\n","\n","    # Iterate over the validation set by batches.\n","    for batch in tqdm(valid_loader):\n","        # A batch consists of image data and corresponding labels.\n","        pid, slice_num, imgs, labels = batch\n","\n","        # We don't need gradient in validation.\n","        # Using torch.no_grad() accelerates the forward process.\n","        with torch.no_grad():\n","            # Forward the data. (Make sure data and model are on the same device.)\n","            images = imgs.to(device)\n","\n","            # Forward pass\n","            logits = model(images)\n","\n","        # We can still compute the loss (but not the gradient).\n","        loss = criterion(logits.view(-1, 512*512), labels.view(-1, 512*512).to(device))  # Calculate the loss\n","\n","        # Compute the accuracy for the current batch.\n","        # acc = (logits.argmax(dim=-1) == labels.to(device)).float().mean()\n","\n","        # Record the loss and accuracy.\n","        valid_loss.append(loss.item())\n","        # valid_accs.append(acc.item())\n","\n","    # The average loss and accuracy for the entire validation set is the average of the recorded values.\n","    valid_loss = sum(valid_loss) / len(valid_loss)\n","    # valid_acc = sum(valid_accs) / len(valid_accs)\n","\n","    # Print the information.\n","    print(f\"[ Valid | {epoch + 1:03d}/{n_epochs:03d} ] loss = {valid_loss:.5f}\") # , acc = {valid_acc:.5f}\n","\n","    # Update logs\n","    if valid_loss <= best_loss:\n","        with open(f\"./{_exp_name}_log.txt\", \"a\") as f:\n","            f.write(f\"[ Valid | {epoch + 1:03d}/{n_epochs:03d} ] loss = {valid_loss:.5f} -> best\\n\") # , acc = {valid_acc:.5f}\n","    else:\n","        with open(f\"./{_exp_name}_log.txt\", \"a\") as f:\n","            f.write(f\"[ Valid | {epoch + 1:03d}/{n_epochs:03d} ] loss = {valid_loss:.5f}\\n\") # , acc = {valid_acc:.5f}\n","\n","    # Save models\n","    if valid_loss <= best_loss:\n","        print(f\"Best model found at epoch {epoch}, saving model\")\n","        torch.save(model.state_dict(), f\"{_exp_name}_best.ckpt\")  # Save the best model to prevent output memory exceed error\n","        best_loss = valid_loss\n","        stale = 0\n","    else:\n","        stale += 1\n","        if stale > patience:\n","            print(f\"No improvement for {patience} consecutive epochs. Early stopping.\")\n","            break"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wWFkdiF6zsaK"},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat":4,"nbformat_minor":0}